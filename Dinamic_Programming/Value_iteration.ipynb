{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3149d231-ae42-407e-9854-2e7ba6e949ba",
   "metadata": {},
   "source": [
    "### VALUE ITERATION USANDO MONTECARLO BACKWARDS\n",
    "Non calcolo nessuna policy ma trovo la value function ottima dopo un numero molto basso di step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fea427f0-7242-4cdc-b286-ba2165eb5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def map_to_state(grid_position, grid_size)-> int:\n",
    "    return grid_position[0] * grid_size + grid_position[1]   \n",
    "\n",
    "def action_to_direction(action):\n",
    "    direction = {\n",
    "            0: np.array([1,0]),      # Giu\n",
    "            1: np.array([0, 1]),     # Destra\n",
    "            2: np.array([-1, 0]),    # Su\n",
    "            3: np.array([0, -1]),    # Sinistra\n",
    "        }   \n",
    "    return direction[action]\n",
    "    \n",
    "def valid_cell(cell, grid_size) -> bool:\n",
    "    if cell[0] < 0 or cell[1] < 0:\n",
    "        return False\n",
    "    elif cell[0] < grid_size and cell[1] < grid_size:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b55be4c2-2e2c-4046-a25f-12d6004d41e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6 -5 -4 -3]\n",
      " [-5 -4 -3 -2]\n",
      " [-4 -3 -2 -1]\n",
      " [-3 -2 -1  0]]\n"
     ]
    }
   ],
   "source": [
    "grid_size = 4\n",
    "states = np.array([], dtype=int)\n",
    "\n",
    "# Trasformo tutte le posizioni della griglia in stati\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        states = np.append(states, map_to_state([i,j], grid_size))\n",
    "\n",
    "V = np.full(states.shape, 0)\n",
    "R = -1.0 * np.ones(len(states))\n",
    "\n",
    "# Elenco possibili azioni\n",
    "actions = [0, 1, 2, 3]\n",
    "\n",
    "# Policy associata a ogni stato\n",
    "Policy = {}\n",
    "for state in states:\n",
    "    Policy[state] = 0.25*np.ones(4)\n",
    "    \n",
    "# Probabilità di transizione associate alle azioni\n",
    "Pa = {}\n",
    "for k in actions:\n",
    "    Pa[k] = np.zeros((len(states), len(states)))\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            curr_cell = [i,j]\n",
    "            curr_state = map_to_state(curr_cell, grid_size)\n",
    "            next_cell = curr_cell + action_to_direction(k)\n",
    "\n",
    "            # Se la cella è nella gridmap, la probabilità di spostarmi in quella cella è 1\n",
    "            if valid_cell(next_cell, grid_size):\n",
    "                next_state = map_to_state(next_cell, grid_size)\n",
    "                Pa[k][curr_state, next_state] = 1\n",
    "                \n",
    "            # Se la cella è fuori dalla gridmap, resto nella cella corrente con probabilità 1\n",
    "            else:\n",
    "                Pa[k][curr_state, curr_state] = 1\n",
    "\n",
    "# Imposto la posizione dei goal. \n",
    "# Vengono modellati come stati dai quali non posso uscire e che non danno nessuna reward negativa ad ogni step\n",
    "goals_pos = [grid_size-1, grid_size-1]\n",
    "goals_states = [map_to_state(goals_pos, grid_size)]\n",
    "\n",
    "for state in goals_states:\n",
    "    R[state] = 0\n",
    "    # Quando mi trovo nel goal, ogni azione che eseguo mi lascia nel goal con p = 1\n",
    "    for k in actions:\n",
    "        Pa[k][state,:] = 0\n",
    "        Pa[k][state,state] = 1\n",
    "\n",
    "episodes_per_step = 10\n",
    "for episode in range(episodes_per_step):\n",
    "    for s in states:\n",
    "        V_buffer = np.zeros(len(actions))\n",
    "        for a in actions:\n",
    "            # Array contentente le possibili value function di V[s], corrispondenti ad ogni possibile azione\n",
    "            V_buffer[a] = R[s] + sum(Pa[a][s]*V)\n",
    "        # Associo ad ogni stato la value fun corrispondente all'azione che mi da\n",
    "        # il valore massimo di V stessa\n",
    "        V[s] = np.max(V_buffer)\n",
    "\n",
    "V_matrix = V.reshape((grid_size, grid_size))\n",
    "print(V_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51b8e9-c31b-4365-a5f0-6c9810132521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
