{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "790d8563-e4c6-4aa4-9745-0826211952aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gridworld\n",
    "import numpy as np\n",
    "\n",
    "def map_to_state(grid_position, grid_size)-> int:\n",
    "    return grid_position[0] * grid_size + grid_position[1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead0684e-9af7-46fc-b8a9-8e1e2ff8dbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-63.48310756 -60.45167808 -56.42717339 -51.68893867]\n",
      " [-60.31675839 -58.73371422 -51.69690901 -42.74012462]\n",
      " [-56.68102476 -54.98407117 -41.80495216 -21.07711644]\n",
      " [-52.2689768  -39.35071385 -25.09799679   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "grid_size = 4\n",
    "n_episodes = 1000\n",
    "\n",
    "env = gym.make(\"GridWorld-v0\", random_start=True, random_goal=False, size=grid_size)\n",
    "\n",
    "# Array di tutti gli stati\n",
    "states = np.array([], dtype=int)\n",
    "\n",
    "# Trasformo tutte le posizioni della griglia in stati\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        states = np.append(states, map_to_state([i,j], grid_size))\n",
    "\n",
    "# Guess iniziale della value function \n",
    "V = np.full(states.shape, 0.0)\n",
    "alpha = 0.2\n",
    "gamma = 1\n",
    "\n",
    "\n",
    "# Sampling\n",
    "for i in range(n_episodes):\n",
    "    observation, info = env.reset()\n",
    "    done = False\n",
    "    curr_cell = observation['agent']\n",
    "    goal_cell = observation['target']\n",
    "\n",
    "    if np.array_equal(curr_cell, goal_cell):\n",
    "        print('Error! START == GOAL')\n",
    "    curr_state = map_to_state(curr_cell, grid_size)\n",
    "    \n",
    "    while not done:\n",
    "        # Eseguo uno step avanti\n",
    "        action = env.action_space.sample()\n",
    "        observation, next_reward, terminated, truncated, info = env.step(action)\n",
    "        next_cell = observation['agent']\n",
    "        next_state = map_to_state(next_cell, grid_size)\n",
    "\n",
    "        V[curr_state] = V[curr_state] + alpha * (next_reward + gamma * V[next_state] - V[curr_state])\n",
    "        done = terminated or truncated\n",
    "        curr_state = next_state\n",
    "        \n",
    "V_matrix = V.reshape((grid_size, grid_size))\n",
    "print(V_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482da4c-97c8-4558-a53f-5a729a043ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
