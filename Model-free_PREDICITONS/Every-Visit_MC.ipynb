{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee1f73ab-affe-49be-9dd9-d5b4c85abc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gridworld\n",
    "import numpy as np\n",
    "\n",
    "def map_to_state(grid_position, grid_size)-> int:\n",
    "    return grid_position[0] * grid_size + grid_position[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ef5babb-b9f0-49aa-9564-4d3e4ffdbd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-53.15589908 -50.2545382  -48.19260401 -45.30290323]\n",
      " [-52.37873621 -48.38970766 -43.04086467 -37.86179159]\n",
      " [-48.67604938 -44.65356833 -35.29288856 -33.52769679]\n",
      " [-47.21033105 -39.31167546 -33.34062293   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "grid_size = 4\n",
    "Incremental_mean = True\n",
    "\n",
    "env = gym.make('GridWorld-v0', random_start=False, random_goal=False, size=grid_size)\n",
    "\n",
    "# Array di tutti gli stati\n",
    "states = np.array([], dtype=int)\n",
    "\n",
    "# Trasformo tutte le posizioni della griglia in stati\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        states = np.append(states, map_to_state([i,j], grid_size))\n",
    "\n",
    "# Counter numero di visite\n",
    "N = np.full(states.shape, 0)\n",
    "\n",
    "# Somma di return associati allo stato\n",
    "S = np.full(states.shape, 0)\n",
    "\n",
    "# Value function\n",
    "V = np.full(states.shape, 0.0)\n",
    "\n",
    "n_episodes = 1000\n",
    "for episode in range(n_episodes):\n",
    "    observation, info = env.reset()\n",
    "    curr_cell = observation['agent']\n",
    "    curr_state = map_to_state(curr_cell, grid_size)\n",
    "    done = False\n",
    "\n",
    "    # Sequenza EP\n",
    "    state_seq = np.array([], dtype=int)\n",
    "    reward_seq = np.array([], dtype=int)\n",
    "    \n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, terminated, truncated, info = env.step(action)   \n",
    "\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        if not done:\n",
    "            state_seq = np.append(state_seq, curr_state)\n",
    "            reward_seq = np.append(reward_seq, reward)\n",
    "\n",
    "        # Next state\n",
    "        curr_cell = observation['agent']\n",
    "        curr_state = map_to_state(curr_cell, grid_size)\n",
    "\n",
    "    for i in range(len(state_seq)):\n",
    "        s = state_seq[i]\n",
    "\n",
    "        N[s] += 1\n",
    "        Gt = sum(reward_seq[i::])\n",
    "        S[s] += Gt\n",
    "        \n",
    "        if Incremental_mean:\n",
    "           V[s] = V[s] + (Gt - V[s])/N[s] \n",
    "        else:\n",
    "            V[s] = S[s]/N[s]\n",
    "        \n",
    "env.close()\n",
    "\n",
    "V_matrix = V.reshape((grid_size, grid_size))\n",
    "print(V_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d8c58-9cdd-4123-a873-0195102f6f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
