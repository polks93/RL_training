{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1e2946-4c85-4b40-8a14-18609d73544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import my_package\n",
    "from my_package import DQN, ReplayBuffer, select_action, optimize_model, eps_decay, soft_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74db70de-c3a9-4b5f-8684-025e80ba8842",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gamma = 0.99\n",
    "alpha = 0.0001\n",
    "\n",
    "eps_max = 1.0\n",
    "eps_min = 0.1\n",
    "exploration_fraction = 1.0\n",
    "\n",
    "hidden_layer_dim = 128\n",
    "target_soft_update = True\n",
    "tau = 0.001\n",
    "\n",
    "buffer_size = 100000\n",
    "batch_size = 256\n",
    "max_episodes = 10\n",
    "data_window = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03deaf2b-84a4-448f-ba44-2684b93df0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paolo\\miniconda3\\envs\\gymenv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\paolo\\miniconda3\\envs\\gymenv\\Lib\\site-packages\\numpy\\_core\\_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1/10, MA Reward: -9.73, MA loss: nan, Eps: 0.90\n",
      "Ep 2/10, MA Reward: -9.52, MA loss: 1.1598, Eps: 0.80\n",
      "Ep 3/10, MA Reward: -10.15, MA loss: 0.0267, Eps: 0.70\n",
      "Ep 4/10, MA Reward: -11.62, MA loss: 1.0475, Eps: 0.60\n",
      "Ep 5/10, MA Reward: -11.15, MA loss: 0.0446, Eps: 0.50\n",
      "Ep 6/10, MA Reward: -10.65, MA loss: 0.3670, Eps: 0.40\n",
      "Ep 7/10, MA Reward: -11.67, MA loss: 1.2424, Eps: 0.30\n",
      "Ep 8/10, MA Reward: -12.77, MA loss: 0.8690, Eps: 0.20\n",
      "Ep 9/10, MA Reward: -10.37, MA loss: 0.0107, Eps: 0.10\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::copy_        18.05%        1.986s        22.46%        2.472s      91.906us        6.203s        35.80%        8.749s     325.321us         26893  \n",
      "                                               aten::to         1.68%     185.122ms        25.01%        2.751s     149.590us      72.667ms         0.42%        6.372s     346.447us         18393  \n",
      "                                         aten::_to_copy         4.30%     473.425ms        23.32%        2.566s     150.851us     105.449ms         0.61%        6.300s     370.299us         17012  \n",
      "                                             aten::item         2.12%     233.570ms        11.58%        1.274s      68.189us      76.681ms         0.44%        2.454s     131.405us         18677  \n",
      "                              aten::_local_scalar_dense         9.45%        1.040s         9.45%        1.040s      55.684us        2.378s        13.72%        2.378s     127.300us         18677  \n",
      "                               Optimizer.step#Adam.step         8.30%     913.323ms        19.17%        2.109s       1.534ms      79.435ms         0.46%        2.245s       1.632ms          1375  \n",
      "                                           aten::linear         2.14%     235.666ms        10.08%        1.109s     104.119us      68.530ms         0.40%        1.893s     177.668us         10656  \n",
      "    autograd::engine::evaluate_function: AddmmBackward0         1.57%     173.135ms         8.49%     934.551ms     226.558us      37.737ms         0.22%        1.732s     419.772us          4125  \n",
      "                                            aten::addmm         4.99%     549.515ms         4.99%     549.515ms      51.569us        1.715s         9.90%        1.715s     160.982us         10656  \n",
      "                                         AddmmBackward0         1.97%     216.669ms         6.13%     674.346ms     163.478us      50.364ms         0.29%        1.416s     343.178us          4125  \n",
      "autograd::engine::evaluate_function: GatherBackward0...         0.30%      32.939ms         2.35%     258.618ms     188.086us       5.755ms         0.03%        1.258s     914.722us          1375  \n",
      "                                        GatherBackward0         0.13%      13.877ms         2.05%     225.679ms     164.130us       5.755ms         0.03%        1.252s     910.537us          1375  \n",
      "                                               aten::mm         1.61%     176.818ms         1.61%     176.818ms      25.719us        1.251s         7.22%        1.251s     181.947us          6875  \n",
      "                                  aten::gather_backward         0.28%      31.353ms         1.93%     211.802ms     154.038us       9.473ms         0.05%        1.246s     906.351us          1375  \n",
      "                                       aten::as_strided         0.55%      60.954ms         0.55%      60.954ms       1.398us        1.240s         7.16%        1.240s      28.444us         43595  \n",
      "                                     aten::scatter_add_         0.84%      92.698ms         0.88%      96.323ms      70.053us      43.567ms         0.25%        1.200s     873.090us          1375  \n",
      "                                aten::_foreach_addcdiv_         1.12%     123.742ms         1.14%     125.165ms      91.029us     166.177ms         0.96%     897.175ms     652.491us          1375  \n",
      "                                      aten::result_type         0.06%       6.850ms         0.06%       6.850ms       0.166us     800.606ms         4.62%     800.606ms      19.409us         41250  \n",
      "                                aten::_foreach_addcmul_         1.18%     129.525ms         1.19%     130.665ms      95.029us     576.216ms         3.33%     593.051ms     431.310us          1375  \n",
      "                                              aten::mul         2.61%     287.124ms         2.61%     287.124ms      14.916us     384.809ms         2.22%     384.809ms      19.990us         19250  \n",
      "                                              aten::sum         0.66%      72.198ms         0.66%      72.198ms      17.503us     269.791ms         1.56%     269.791ms      65.404us          4125  \n",
      "                                                aten::t         3.26%     358.533ms         6.57%     722.313ms      28.017us     107.379ms         0.62%     265.858ms      10.312us         25781  \n",
      "                                    aten::_foreach_div_         1.63%     179.882ms         1.65%     181.336ms     131.881us     147.187ms         0.85%     163.937ms     119.227us          1375  \n",
      "                                        aten::transpose         2.98%     328.372ms         3.31%     363.779ms      14.110us     105.977ms         0.61%     158.479ms       6.147us         25781  \n",
      "                                             aten::relu         1.04%     114.138ms         2.06%     226.562ms      31.892us      28.864ms         0.17%     130.558ms      18.378us          7104  \n",
      "                                    aten::_foreach_sqrt         1.10%     121.248ms         1.40%     153.561ms     111.681us     104.314ms         0.60%     121.211ms      88.153us          1375  \n",
      "autograd::engine::evaluate_function: torch::autograd...         1.00%     109.948ms         2.96%     325.295ms      39.430us      33.742ms         0.19%     118.755ms      14.395us          8250  \n",
      "                                    aten::_foreach_add_         1.81%     198.633ms         2.07%     227.499ms      82.727us      77.423ms         0.45%     113.436ms      41.249us          2750  \n",
      "                                              aten::add         1.02%     111.786ms         1.02%     111.786ms      11.614us     109.125ms         0.63%     109.125ms      11.338us          9625  \n",
      "                                        aten::clamp_min         1.02%     112.423ms         1.02%     112.423ms      15.825us     101.694ms         0.59%     101.694ms      14.315us          7104  \n",
      "                                aten::mse_loss_backward         0.57%      62.654ms         1.59%     174.975ms      63.627us      36.622ms         0.21%      99.035ms      36.013us          2750  \n",
      "                                         aten::mse_loss         0.76%      84.052ms         1.23%     135.392ms      98.467us      29.134ms         0.17%      90.785ms      66.025us          1375  \n",
      "                        torch::autograd::AccumulateGrad         1.03%     113.107ms         1.96%     215.347ms      26.103us      33.756ms         0.19%      85.013ms      10.305us          8250  \n",
      "                                    aten::_foreach_mul_         1.03%     113.030ms         1.04%     114.809ms      83.497us      67.761ms         0.39%      84.635ms      61.553us          1375  \n",
      "autograd::engine::evaluate_function: MseLossBackward...         0.24%      26.635ms         1.88%     207.084ms     150.607us       5.594ms         0.03%      83.335ms      60.607us          1375  \n",
      "                                              aten::max         0.65%      71.132ms         0.67%      74.146ms      53.925us      74.377ms         0.43%      79.984ms      58.170us          1375  \n",
      "                                       MseLossBackward0         0.24%      26.409ms         1.64%     180.448ms     131.235us       5.571ms         0.03%      77.741ms      56.539us          1375  \n",
      "        autograd::engine::evaluate_function: TBackward0         0.53%      57.812ms         1.97%     216.724ms      52.539us      16.841ms         0.10%      75.881ms      18.395us          4125  \n",
      "     autograd::engine::evaluate_function: ReluBackward0         2.40%     263.655ms         3.33%     366.823ms     133.390us      11.305ms         0.07%      72.914ms      26.514us          2750  \n",
      "                                          ReluBackward0         0.37%      41.230ms         0.94%     103.168ms      37.516us      11.151ms         0.06%      61.609ms      22.403us          2750  \n",
      "                                   aten::_foreach_lerp_         0.28%      31.191ms         0.28%      31.191ms      22.684us      61.270ms         0.35%      61.270ms      44.560us          1375  \n",
      "                                          aten::detach_         0.99%     109.019ms         1.09%     119.761ms      12.113us      40.626ms         0.23%      60.664ms       6.136us          9887  \n",
      "                                           aten::detach         0.98%     108.066ms         1.18%     129.792ms      13.485us      40.153ms         0.23%      59.693ms       6.202us          9625  \n",
      "                                             TBackward0         0.38%      41.771ms         1.44%     158.912ms      38.524us      16.813ms         0.10%      59.040ms      14.313us          4125  \n",
      "                                             aten::mean         0.37%      40.464ms         0.39%      42.966ms      31.248us      53.297ms         0.31%      56.061ms      40.772us          1375  \n",
      "                                    aten::empty_strided         1.12%     123.159ms         1.12%     123.159ms       4.622us      54.126ms         0.31%      54.126ms       2.031us         26649  \n",
      "                                            aten::fill_         0.39%      43.242ms         0.39%      43.242ms      10.452us      51.222ms         0.30%      51.222ms      12.381us          4137  \n",
      "                               aten::threshold_backward         0.56%      61.938ms         0.56%      61.938ms      22.523us      50.458ms         0.29%      50.458ms      18.348us          2750  \n",
      "                                           aten::gather         0.70%      76.729ms         0.72%      79.707ms      57.969us      43.747ms         0.25%      49.308ms      35.860us          1375  \n",
      "                                            aten::zero_         0.31%      33.936ms         0.55%      60.261ms      21.818us      11.311ms         0.07%      48.848ms      17.686us          2762  \n",
      "                                       aten::zeros_like         0.30%      32.693ms         0.84%      92.428ms      66.639us       8.479ms         0.05%      46.362ms      33.426us          1387  \n",
      "                                           aten::argmax         0.31%      34.154ms         0.32%      35.006ms      43.648us      39.439ms         0.23%      41.039ms      51.171us           802  \n",
      "                                        aten::new_zeros         0.24%      26.468ms         0.76%      84.126ms      61.183us       8.443ms         0.05%      36.261ms      26.372us          1375  \n",
      "                                        aten::ones_like         0.23%      25.602ms         0.61%      66.732ms      48.532us       8.366ms         0.05%      30.470ms      22.160us          1375  \n",
      "                                        aten::unsqueeze         0.66%      72.476ms         0.73%      80.593ms      18.396us      17.793ms         0.10%      26.746ms       6.105us          4381  \n",
      "                                             aten::rsub         0.24%      25.993ms         0.46%      50.578ms      36.784us       5.599ms         0.03%      23.023ms      16.744us          1375  \n",
      "                                                detach_         0.10%      10.742ms         0.10%      10.742ms       1.086us      20.038ms         0.12%      20.038ms       2.027us          9887  \n",
      "                                       aten::lift_fresh         0.10%      11.322ms         0.10%      11.322ms       1.145us      20.030ms         0.12%      20.030ms       2.026us          9887  \n",
      "autograd::engine::evaluate_function: SqueezeBackward...         0.24%      26.114ms         2.03%     222.973ms     162.162us       5.598ms         0.03%      19.653ms      14.293us          1375  \n",
      "                                                 detach         0.20%      21.726ms         0.20%      21.726ms       2.257us      19.540ms         0.11%      19.540ms       2.030us          9625  \n",
      "                                              aten::sub         0.22%      24.585ms         0.22%      24.585ms      17.880us      17.424ms         0.10%      17.424ms      12.672us          1375  \n",
      "                                       aten::empty_like         0.29%      31.718ms         0.47%      51.606ms      18.684us      11.304ms         0.07%      16.940ms       6.133us          2762  \n",
      "                                             aten::add_         0.25%      27.813ms         0.25%      27.813ms       3.371us      16.864ms         0.10%      16.864ms       2.044us          8250  \n",
      "                                        aten::expand_as         0.24%      26.092ms         0.53%      58.854ms      36.085us       6.621ms         0.04%      16.490ms      10.110us          1631  \n",
      "                                       SqueezeBackward1         1.55%     170.088ms         1.79%     196.859ms     143.170us       5.620ms         0.03%      14.055ms      10.222us          1375  \n",
      "                                            aten::empty         0.29%      31.586ms         0.29%      31.586ms       5.737us      11.229ms         0.06%      11.229ms       2.039us          5506  \n",
      "                                           aten::expand         0.27%      29.477ms         0.30%      32.762ms      20.087us       6.569ms         0.04%       9.869ms       6.051us          1631  \n",
      "                                          aten::squeeze         0.22%      24.676ms         0.23%      25.850ms      18.800us       5.618ms         0.03%       8.434ms       6.134us          1375  \n",
      "                                             aten::view         0.14%      14.872ms         0.14%      14.872ms       3.605us       8.423ms         0.05%       8.423ms       2.042us          4125  \n",
      "                                        aten::new_empty         0.21%      22.575ms         0.27%      29.739ms      21.629us       5.551ms         0.03%       8.332ms       6.060us          1375  \n",
      "                                          aten::resize_         0.02%       1.759ms         0.02%       1.759ms       1.279us       2.801ms         0.02%       2.801ms       2.037us          1375  \n",
      "                                aten::broadcast_tensors         0.02%       2.525ms         0.02%       2.525ms       1.836us       2.797ms         0.02%       2.797ms       2.034us          1375  \n",
      "                     Optimizer.zero_grad#Adam.zero_grad         0.99%     108.732ms         0.99%     108.732ms      79.078us       2.775ms         0.02%       2.775ms       2.018us          1375  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 11.002s\n",
      "Self CUDA time total: 17.328s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('ShipQuest-v0', prox_sensor=True)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "\"\"\" Init neural networks \"\"\"\n",
    "policy_net = DQN(\n",
    "    state_dim=state_dim,\n",
    "    action_dim=action_dim,\n",
    "    device=device,\n",
    "    hidden_dim=hidden_layer_dim,\n",
    ")\n",
    "\n",
    "target_net = DQN(\n",
    "    state_dim=state_dim,\n",
    "    action_dim=action_dim,\n",
    "    device=device,\n",
    "    hidden_dim=hidden_layer_dim,\n",
    ")\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=alpha)\n",
    "\n",
    "\"\"\" Init buffer \"\"\"\n",
    "buffer = ReplayBuffer(capacity=buffer_size)\n",
    "\n",
    "\"\"\" Data collect variables \"\"\"\n",
    "total_rewards = np.zeros(max_episodes)\n",
    "eps_history = np.zeros(max_episodes)\n",
    "len_episodes = np.zeros(max_episodes)\n",
    "loss_history = []\n",
    "reward_collected_per_ep = np.zeros(max_episodes)\n",
    "start_time = time.time()\n",
    "with torch.autograd.profiler.profile(use_device='cuda') as prof:\n",
    "\n",
    "    for episode in range(max_episodes):\n",
    "        state, info = env.reset()\n",
    "        done = False\n",
    "        epsilon = eps_decay(episode, max_episodes, eps_min, eps_max, exploration_fraction, 'linear')\n",
    "        eps_history[episode] = epsilon\n",
    "        \n",
    "        while not done:\n",
    "            action = select_action(state, policy_net, epsilon, action_dim)\n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            buffer.push(state, action, reward, next_state, terminated)\n",
    "            done = terminated or truncated\n",
    "    \n",
    "            # Ottimizzo policy net e soft update target net\n",
    "            if len(buffer) > batch_size:\n",
    "                loss = optimize_model(policy_net, target_net, buffer, optimizer, batch_size, gamma, debug=True)\n",
    "                if target_soft_update:\n",
    "                    soft_update(policy_net, target_net, tau)\n",
    "                # loss_history.append(loss.cpu().detach().numpy())\n",
    "                loss_history.append(loss.item())\n",
    "    \n",
    "            total_rewards[episode] += reward\n",
    "            len_episodes[episode] += 1\n",
    "            state = next_state\n",
    "    \n",
    "    \n",
    "        if episode % data_window == 0 and episode != 0:\n",
    "            ma_reward = np.mean(total_rewards[episode-data_window:episode])\n",
    "            ma_loss = np.mean(loss_history[-data_window:])\n",
    "            print(f\"Ep {episode}/{max_episodes}, MA Reward: {ma_reward:.2f}, MA loss: {ma_loss:.4f}, Eps: {epsilon:.2f}\")\n",
    "    \n",
    "    env.close()\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n",
    "\n",
    "# total_time_seconds = time.time() - start_time\n",
    "# hours = int(total_time_seconds // 3600)\n",
    "# minutes = int((total_time_seconds % 3600) // 60)\n",
    "# seconds = int(total_time_seconds % 60)\n",
    "# print(f\"Training finito in: {hours} ore {minutes} minuti e {seconds} secondi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d43e117-2136-49b9-9bdb-b895187dff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plot rewards \"\"\"\n",
    "window_size = 50\n",
    "ma_reward = np.convolve(total_rewards, np.ones(window_size) / window_size, mode='valid')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(np.arange(len(total_rewards)), total_rewards)\n",
    "plt.plot(np.arange(window_size - 1, max_episodes), ma_reward, color='red', label=f'Moving Average (Window={window_size})', linewidth=2)\n",
    "plt.title('Total Reward and Moving Average Over Episodes')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\"\"\" Plot loss per step \"\"\"\n",
    "window_size = 1000\n",
    "ma_loss = np.convolve(loss_history, np.ones(window_size) / window_size, mode='valid')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.arange(len(loss_history)), loss_history, label='Loss per Step')\n",
    "plt.plot(np.arange(window_size - 1, len(loss_history)), ma_loss, color='red', label=f'Moving Average (Window={window_size})', linewidth=2)\n",
    "plt.title('Loss per Step')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\" Plot episode duration \"\"\"\n",
    "window_size = 50\n",
    "ma_steps = np.convolve(len_episodes, np.ones(window_size) / window_size, mode='valid')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(np.arange(len(len_episodes)), len_episodes)\n",
    "plt.plot(np.arange(window_size - 1, max_episodes), ma_steps, color='red', label=f'Moving Average (Window={window_size})', linewidth=2)\n",
    "plt.title('Steps per Episode and Moving Average Over Episodes')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total steps')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415091d4-1548-4f42-ac56-84c7e7d916bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('ShipQuest-v0', render_mode='human', prox_sensor=True)\n",
    "\n",
    "for ep in range(5):\n",
    "    state, info = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action = select_action(state, policy_net, 0, action_dim)\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "    print('total reward: ' + str(total_reward))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff8094-04f6-4037-b652-cd323bdae8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'gamma' : gamma,\n",
    "    'alpha' : alpha,\n",
    "    'eps_max' : eps_max,\n",
    "    'eps_min' : eps_min,\n",
    "    'exploration_fraction' : exploration_fraction,\n",
    "    'state_dim': state_dim,\n",
    "    'action_dim': action_dim,\n",
    "    'hidden_layer_dim' : hidden_layer_dim,\n",
    "    'target_soft_update' : target_soft_update,\n",
    "    'tau' : tau,\n",
    "    'buffer_size' : buffer_size,\n",
    "    'batch_size' : batch_size,\n",
    "    'max_episodes' : max_episodes,\n",
    "    'model_state_dict': policy_net.state_dict(),\n",
    "    'total_rewards': total_rewards,\n",
    "    'loss_history' : loss_history,\n",
    "    'len_episodes' : len_episodes,\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'model_with_data_10000_ep.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae35c04-bf80-47fa-8b6d-40bc58545cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
