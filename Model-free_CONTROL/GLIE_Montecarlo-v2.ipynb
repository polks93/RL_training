{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcff667-413c-419b-bdc2-7fdb70305352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gridworld\n",
    "import numpy as np\n",
    "\n",
    "def map_to_state(grid_position, grid)-> int:\n",
    "    max_cols = grid[1]\n",
    "    return grid_position[0] * max_cols + grid_position[1] \n",
    "\n",
    "def mu_policy(Qs, epsilon) -> int:\n",
    "\n",
    "    N = len(Qs)\n",
    "\n",
    "    # Azione random\n",
    "    if np.random.rand() < epsilon:\n",
    "        action = np.random.randint(0,N)\n",
    "        \n",
    "    # Azione greedy \n",
    "    else:\n",
    "        action = pi_policy(Qs)\n",
    "        \n",
    "    return action\n",
    "\n",
    "# La polica pi Ã¨ puramente GREEDY: Sceglie sempre l'azione con il valore massimo di Q(s,a)\n",
    "def pi_policy(Qs):\n",
    "\n",
    "    Qmax = np.max(Qs)\n",
    "    id = np.where(Qs == Qmax)[0]\n",
    "    \n",
    "    if len(id) > 1:\n",
    "        action = np.random.choice(id)\n",
    "    else:\n",
    "        action = id[0]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f3efd4-8c15-492a-a64b-608af63b7829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "0.6065306597126334\n",
      "Goal reached 1 times\n",
      "200\n",
      "0.36787944117144233\n",
      "Goal reached 33 times\n",
      "300\n",
      "0.22313016014842982\n",
      "Goal reached 102 times\n",
      "400\n",
      "0.1353352832366127\n",
      "Goal reached 184 times\n",
      "500\n",
      "0.0820849986238988\n",
      "Goal reached 272 times\n",
      "600\n",
      "0.049787068367863944\n",
      "Goal reached 367 times\n",
      "700\n",
      "0.0301973834223185\n",
      "Goal reached 464 times\n",
      "800\n",
      "0.01831563888873418\n",
      "Goal reached 562 times\n",
      "900\n",
      "0.011108996538242306\n",
      "Goal reached 662 times\n",
      "1000\n",
      "0.006737946999085467\n",
      "Goal reached 762 times\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Cliff-v0\")\n",
    "\n",
    "max_epsilon = 1.0                  # Exploration probability at start\n",
    "min_epsilon = 0.0                 # Minimum exploration probability (start exploiting)\n",
    "decay_rate = 0.005               # Exponential decay rate for exploration prob\n",
    "num_episodes = 1000\n",
    "gamma = 0.99\n",
    "\n",
    "goal = 0\n",
    "\n",
    "# Vettore contenente gli stati\n",
    "states = np.array([], dtype=int)\n",
    "\n",
    "# Dimensioni griglia\n",
    "max_rows = 4\n",
    "max_cols = 12\n",
    "grid = [max_rows, max_cols]\n",
    "\n",
    "# Trasformo tutte le posizioni della griglia in stati \n",
    "for i in range(max_rows):\n",
    "    for j in range(max_cols):\n",
    "        curr_state = map_to_state([i,j], grid)\n",
    "        states = np.append(states, curr_state)\n",
    "        \n",
    "\n",
    "# Dizionario contenente le Action Value Function per ogni stato\n",
    "# e dizionario counter coppia stato-azione\n",
    "Q ={}\n",
    "N = {}\n",
    "for s in states:\n",
    "    Q[s] = np.zeros(4)\n",
    "    N[s] = np.zeros(4)\n",
    "    \n",
    "for ep in range(1, num_episodes+1):\n",
    "    \n",
    "    epsilon = np.max([min_epsilon, max_epsilon * np.exp(-decay_rate * ep)])\n",
    "    curr_cell, info = env.reset()\n",
    "    curr_state = map_to_state(curr_cell, grid)\n",
    "    done = False\n",
    "    steps = 0\n",
    "    \n",
    "    # Sequenza EP\n",
    "    state_seq = np.array([], dtype=int)\n",
    "    action_seq = np.array([], dtype=int)\n",
    "    reward_seq = np.array([], dtype=int)\n",
    "\n",
    "    while not done:\n",
    "        \n",
    "        action = mu_policy(Q[curr_state], epsilon)\n",
    "        next_cell, reward, terminated, truncated, info = env.step(action)\n",
    "        if terminated and reward == -1:\n",
    "            goal +=1 \n",
    "        \n",
    "        state_seq = np.append(state_seq, curr_state)\n",
    "        action_seq = np.append(action_seq, action)\n",
    "        reward_seq = np.append(reward_seq, reward)\n",
    "\n",
    "        curr_state = map_to_state(next_cell, grid)\n",
    "        steps += 1\n",
    "        \n",
    "        done = terminated or truncated\n",
    "\n",
    "    if ep % 100 == 0:\n",
    "        print(ep)\n",
    "        print(epsilon)\n",
    "        print(\"Goal reached %d times\" % goal)\n",
    "    if not truncated:    \n",
    "        for i in range(len(state_seq)):\n",
    "            s = state_seq[i]\n",
    "            a = action_seq[i]\n",
    "            N[s][a] += 1\n",
    "            \n",
    "            discount_factors = np.power(gamma, np.arange(len(reward_seq[i:])))\n",
    "            Gt = discounted_return = np.sum(reward_seq[i:] * discount_factors)\n",
    "            Q[s][a] = Q[s][a] + (Gt - Q[s][a])/N[s][a]\n",
    "        \n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd797f9a-1e0f-4c2d-8628-3ce72ba9b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Cliff-v0\", render_mode='human')\n",
    "for ep in range(5):\n",
    "\n",
    "    curr_cell, info = env.reset()\n",
    "    curr_state = map_to_state(curr_cell, grid)\n",
    "    done = False\n",
    "    steps = 0\n",
    "\n",
    "    while not done:\n",
    "        \n",
    "        action = mu_policy(Q[curr_state], 0)\n",
    "        next_cell, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        curr_state = map_to_state(next_cell, grid)\n",
    "        if reward == 0:\n",
    "            print(\"GOAL REACHED!\")\n",
    "    \n",
    "        steps += 1\n",
    "        \n",
    "        done = terminated or truncated\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ab42f-1355-4a75-904b-e76c6df83ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
