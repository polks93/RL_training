{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20b7548-4291-42ec-95ef-f17a1458bea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.11.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.envs.registration import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8879c595-bf26-42fc-a88d-83a4d5e378a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 30}\n",
    "\n",
    "    def __init__(self, render_mode=None, size=5):\n",
    "        self.size = size\n",
    "        self.window_size = 512\n",
    "\n",
    "        # Definisco lo spazio delle osservazioni un dizionario contente la posizione dell'agente e quella del target\n",
    "        self.observation_space = spaces.Dict(\n",
    "            { \n",
    "                \"agent\": spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
    "                \"target\": spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Definisco lo spazio delle azioni, saranno 4 possibili azioni NSEW\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "\n",
    "        # Conversione da azione discreta a movimento\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([1,0]),\n",
    "            1: np.array([0, 1]),\n",
    "            2: np.array([-1, 0]),\n",
    "            3: np.array([0, -1]),\n",
    "        }       \n",
    "\n",
    "        # Imposto la render mode, se passata correttamente altrimenti passo un errore\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "\n",
    "    # Funzione per ottenere direttamente le osservazioni \n",
    "    def _get_obs(self):\n",
    "        return {\"agent\": self._agent_location, \"target\": self._target_location}\n",
    "\n",
    "    # Funzione per ottenere direttamente le info\n",
    "    def _get_info(self):\n",
    "        return {\n",
    "            \"distance\": np.linalg.norm(\n",
    "                self._agent_location - self._target_location, ord=1\n",
    "            )\n",
    "        }\n",
    "\n",
    "    # Funzione reset. Serve per inizializzare l'ambiente all'inizio di ogni nuovo episodio\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # super() va a richiamare un attributo della classe genitore gym.Env\n",
    "        # In questo caso serve ad assegnare un eventuale seed casuale\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # Posizione iniziale agente random\n",
    "        self._agent_location = self.np_random.integers(0, self.size, size=2, dtype=int)\n",
    "\n",
    "        # Posizione del target. Viene campionata in modo da non coincidere con la posizione\n",
    "        #  dell'agente\n",
    "        self._target_location = self._agent_location\n",
    "        while np.array_equal(self._target_location, self._agent_location):\n",
    "            self._target_location = self.np_random.integers(0, self.size, size=2, dtype=int)\n",
    "\n",
    "        # Uso le funzioni dichiarate sopra per ottenre le osservazioni e le info\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    # Funzione step. Serve a eseguire un ciclo dopo aver deciso un azione, si puo chiamare solo dopo reset\n",
    "    def step(self, action):\n",
    "        # Ottiene la direzione di movimento dall'azione binaria\n",
    "        direction = self._action_to_direction[action]\n",
    "\n",
    "        # Update posizione agente. np.clip serve a restare nel box [0 1 2 3 4]\n",
    "        self._agent_location = np.clip(self._agent_location + direction, 0, self.size - 1)\n",
    "\n",
    "        # Check raggiungimento target\n",
    "        terminated = np.array_equal(self._agent_location, self._target_location)\n",
    "\n",
    "        # Definizione reward. Viene ottenuta solo se raggiungo il target\n",
    "        if terminated:\n",
    "            reward = 1\n",
    "        else: \n",
    "            reward = 0\n",
    "\n",
    "        # Ottengo osservazioni e info\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, reward, terminated, False, info\n",
    "\n",
    "\n",
    "    # Funzione di rendering basata su Pygame\n",
    "    def render(self):\n",
    "        if self.render_mode== \"rgb_array\":\n",
    "            return self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
    "        if self.clock is None and self.render_mode == \"human\":\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        # Genero un buffer su cui disegnare l'ambiente prima di disengarlo sullo schermo\n",
    "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
    "        canvas.fill((255, 255, 255))\n",
    "        pix_square_size = (self.window_size/self.size)\n",
    "\n",
    "        # Inizio a disegnare il target\n",
    "        pygame.draw.rect(\n",
    "            canvas,\n",
    "            (255, 0, 0),\n",
    "            pygame.Rect(\n",
    "                pix_square_size*self._target_location, \n",
    "                (pix_square_size, pix_square_size),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Disegno agente\n",
    "        pygame.draw.circle(\n",
    "            canvas,\n",
    "            (0, 0, 255),\n",
    "            (self._agent_location + 0.5) * pix_square_size,\n",
    "            pix_square_size / 3,\n",
    "        )\n",
    "\n",
    "        # Disegno la griglia\n",
    "        for x in range(self.size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (0, pix_square_size * x),\n",
    "                (self.window_size, pix_square_size * x),\n",
    "                width=3,\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (pix_square_size * x, 0),\n",
    "                (pix_square_size * x, self.window_size),\n",
    "                width=3,\n",
    "            )\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            # Copio il buffer appena creato su una finestra visibile\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            #  Mi assicuro di mantenere il framerate\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else: # rgb_array\n",
    "            return np.transpose(np.array(pygame.surfarray.pixels3d(canvas)), axes=(1,0,2))\n",
    "\n",
    "    # Funzione per chiudere la finestra di rendering\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "\n",
    "\n",
    "# Registrazione env\n",
    "from gymnasium.envs.registration import register\n",
    "\n",
    "register(\n",
    "    id='GridWorld-v0', \n",
    "    entry_point='__main__:GridWorldEnv',  \n",
    "    max_episodes_step=300,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf5d452-5a83-4dfb-8acb-aa1f9a367049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo classe env del tipo GridWorld\n",
    "env = gym.make('GridWorld-v0', render_mode=\"human\")\n",
    "\n",
    "#  Init dell'amnbiente\n",
    "observation, info = env.reset()\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()  # agent policy that uses the observation and info\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d5269b-e6ad-4a62-9254-152e65d4b2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
